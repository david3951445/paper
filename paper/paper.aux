\relax 
\citation{9700861}
\citation{8352646}
\citation{chen2019control}
\citation{9371292}
\citation{9476736}
\citation{zhang2018path}
\citation{9108245}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{}\protected@file@percent }
\citation{arbanas2018decentralized}
\citation{9384209}
\citation{olcay2017design}
\citation{8931370}
\citation{wang2022consensus}
\citation{6669235}
\citation{paden2016survey}
\citation{Khamis2015}
\@writefile{toc}{\contentsline {section}{\numberline {II}PRELIMINARIES OF URTS in S\&R usage}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Task Allocation}{3}{}\protected@file@percent }
\citation{elbanhawi2014sampling}
\citation{liu2018survey}
\citation{elbanhawi2014sampling}
\citation{elbanhawi2014sampling}
\citation{yu2013multi}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The system architecture of agent in URTS. The 2 blocks on left hand side are used to convert the low-level sensor information into high-level information, such as map, start point and object information. The 5 blocks on right hand side are the flow of an agent performing a S\&R mission. From the top to the bottom, it is the decision of the task position, the planning of the path, the decision of the behavior, the planning of the local motion trajectory, and the low-level tracking control.\relax }}{4}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:sys}{{1}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Path Planning}{4}{}\protected@file@percent }
\newlabel{asm:collision}{{2.4}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-C}}Behavior Layer}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-D}}Local Motion Planning}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-E}}Tracking Control}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}system description of UAVs and biped robots in URTS}{5}{}\protected@file@percent }
\newlabel{asm:cc again}{{3.1}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The structure of behavior layer. The leaves of the tree structure are the possible behaviors an agent can take. The behavior to be took at every moment will be decided in this block.\relax }}{6}{}\protected@file@percent }
\newlabel{fig:behavior}{{2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The flowchart of local motion planning. The corresponding motion planning will be executed according to the behavior determined by the behavior layer. The exception terminator in figure represents an exceptional condition that performs unconsidered behaviors. The reference path $r[k]$ is a sequence (or say a discrete signal) designed by a specific behavior block.\relax }}{6}{}\protected@file@percent }
\newlabel{fig:LocalMotionPlanning}{{3}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The flowchart of Flying and Walking. In both blocks, a smoothed path is obtained by post-processing first. Then the respective motion of behavior is designed. The final outputs of Flying and Walking are all desired reference path $r[k]$, but its value and dimension will vary according to the dimension of the system model.\relax }}{6}{}\protected@file@percent }
\newlabel{fig:FandW}{{4}{6}}
\citation{sabatino2015quadrotor}
\citation{ourrobot}
\citation{kajita2001real}
\citation{ourrobot}
\citation{huang2001planning}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}motion planning of flying of UAV}{7}{}\protected@file@percent }
\newlabel{eq:uav}{{3}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}motion of walking of robot}{7}{}\protected@file@percent }
\newlabel{eq:robot}{{4}{7}}
\citation{1241826}
\citation{lewis2012optimal}
\newlabel{eq:LIPM}{{6}{8}}
\newlabel{eq:output tracking}{{7}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Tracking control of each agent in hybrid URTS}{8}{}\protected@file@percent }
\newlabel{eq:agent}{{8}{8}}
\newlabel{eq:control}{{9}{8}}
\citation{9834947}
\citation{9075385}
\citation{chen2013human}
\citation{9834947}
\citation{9306757}
\newlabel{eq:UAV couple}{{10}{9}}
\newlabel{eq:robot couple}{{11}{9}}
\newlabel{eq:agent d1}{{12}{9}}
\newlabel{eq:agent1}{{13}{9}}
\newlabel{eq:error, state eq}{{14}{9}}
\newlabel{eq:linear f1}{{15}{9}}
\newlabel{eq:agent output}{{16}{9}}
\newlabel{eq:error}{{17}{9}}
\newlabel{eq:smooth model}{{18}{9}}
\citation{boyd1994linear}
\citation{boyd1994linear}
\newlabel{eq:e_bar}{{19}{10}}
\newlabel{eq:e_hat}{{20}{10}}
\newlabel{eq:u_fb}{{21}{10}}
\newlabel{eq:e_tilde}{{22}{10}}
\newlabel{eq:x_tilde}{{23}{10}}
\newlabel{Hinf}{{24}{10}}
\newlabel{lemma1}{{1}{10}}
\newlabel{lemma2}{{2}{10}}
\newlabel{theorem1}{{1}{10}}
\newlabel{BMI1}{{27}{10}}
\newlabel{pf:1}{{28}{10}}
\newlabel{pf:2}{{29}{10}}
\newlabel{pf:3}{{IV}{11}}
\newlabel{eq:M}{{30}{11}}
\newlabel{eq:step1}{{31}{11}}
\newlabel{eq:step2}{{32}{11}}
\newlabel{LMI constraint}{{33}{11}}
\newlabel{eq:linear subsys}{{34}{11}}
\citation{ourrobot}
\@writefile{toc}{\contentsline {section}{\numberline {V}simulation results}{12}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The flowchart of tracking control in the hybrid URTS. The control scheme of UAV and robot in URTS is only different from the reference generator block. The reason is that the underactuated nature of the UAV imposes the limitation on the control input and reference trajectory. By introducing this block, a general $H_\infty $ decentralized observer-based feedforward-linearized PID FTC for an agent in URTS is proposed.\relax }}{13}{}\protected@file@percent }
\newlabel{fig:tracking}{{5}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces An example of a S\&R area in URTS. This area is divided into $N_T$ areas, and $team_i$ is responsible for $area_i$\relax }}{13}{}\protected@file@percent }
\newlabel{fig:SR_area}{{6}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The search tasks in the $i$th team at the begining. The search tasks $T_j,j=1,2,...,5$ are to reach some consecutive destinations $q_{goal}$ (black dots in figure). For robots, $q_{goal}$ will be passed to path planning block to find collision-free paths $(\sigma _n)$. For UAV, the sequence formed by $q_{goal}$ is directly the path $(\sigma _n)$ due to the no-collision assumption.\relax }}{13}{}\protected@file@percent }
\newlabel{fig:S_task}{{7}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The path planning result of robot using RRT algorithm. The block polygons represent the obstacle space $\mathcal  {C}_{obs}$.\relax }}{14}{}\protected@file@percent }
\newlabel{fig:R_task}{{8}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The result of local motion planning of UAV flying.\relax }}{14}{}\protected@file@percent }
\newlabel{sim:flying}{{9}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The top view of result of local motion planning of robot walking. The joint path, i.e., reference path $r[k]$ will be obtained by solving IK with CoM, left foothold and right foothold path.\relax }}{14}{}\protected@file@percent }
\newlabel{sim:walking}{{10}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The trajectories of reference, state and estimated state of the UAV $\alpha _{i,1}$\relax }}{14}{}\protected@file@percent }
\newlabel{fig:UAV, state}{{11}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The estimation of actuator fault of the UAV $\alpha _{i,1}$\relax }}{14}{}\protected@file@percent }
\newlabel{fig:UAV, fa}{{12}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The estimation of sensor fault of the UAV $\alpha _{i,1}$\relax }}{14}{}\protected@file@percent }
\newlabel{fig:UAV, fs}{{13}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces The control effort of the UAV $\alpha _{i,1}$\relax }}{15}{}\protected@file@percent }
\newlabel{fig:UAV, control}{{14}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces The trajectories of reference, state and estimated state of the robot $\alpha _{i,2}$\relax }}{15}{}\protected@file@percent }
\newlabel{fig:robot, state}{{15}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces The estimation of actuator fault of the robot $\alpha _{i,2}$.\relax }}{15}{}\protected@file@percent }
\newlabel{fig:robot, fa}{{16}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces The estimation of sensor fault of the robot $\alpha _{i,2}$\relax }}{15}{}\protected@file@percent }
\newlabel{fig:robot, fs}{{17}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces The control effort of the robot $\alpha _{i,2}$\relax }}{15}{}\protected@file@percent }
\newlabel{fig:robot, control}{{18}{15}}
\bibstyle{unsrt}
\bibdata{citation}
\bibcite{9700861}{1}
\bibcite{8352646}{2}
\bibcite{chen2019control}{3}
\bibcite{9371292}{4}
\bibcite{9476736}{5}
\bibcite{zhang2018path}{6}
\bibcite{9108245}{7}
\bibcite{arbanas2018decentralized}{8}
\bibcite{9384209}{9}
\bibcite{olcay2017design}{10}
\bibcite{8931370}{11}
\bibcite{wang2022consensus}{12}
\bibcite{6669235}{13}
\bibcite{paden2016survey}{14}
\bibcite{Khamis2015}{15}
\bibcite{elbanhawi2014sampling}{16}
\bibcite{liu2018survey}{17}
\bibcite{yu2013multi}{18}
\bibcite{sabatino2015quadrotor}{19}
\bibcite{ourrobot}{20}
\bibcite{kajita2001real}{21}
\bibcite{huang2001planning}{22}
\bibcite{1241826}{23}
\bibcite{lewis2012optimal}{24}
\bibcite{9834947}{25}
\bibcite{9075385}{26}
\bibcite{chen2013human}{27}
\bibcite{9306757}{28}
\bibcite{boyd1994linear}{29}
\@writefile{toc}{\contentsline {section}{\numberline {VI}conclusion}{16}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{REFERENCES}{16}{}\protected@file@percent }
\gdef \@abspage@last{16}
