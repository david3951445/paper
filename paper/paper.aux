\relax 
\citation{8352646}
\citation{9476736}
\citation{9108245}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{}\protected@file@percent }
\citation{9384209}
\citation{8931370}
\citation{6669235}
\citation{paden2016survey}
\citation{Khamis2015}
\@writefile{toc}{\contentsline {section}{\numberline {II}PRELIMINARIES OF S\&R URTS}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The system architecture of agent in URTS. The 2 blocks on left side are used to convert low-level sensor information into high-level information, such as map, start point and object information. The 5 blocks on right side are the flow of an agent performing a S\&R mission. From top to bottom, it is the decision of the task position, the planning of the path, the decision of the behavior, the planning of the local motion trajectory, and the low-level tracking control\relax }}{3}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:sys}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Task Allocation}{3}{}\protected@file@percent }
\citation{elbanhawi2014sampling}
\citation{liu2018survey}
\citation{elbanhawi2014sampling}
\citation{elbanhawi2014sampling}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Path Planning}{4}{}\protected@file@percent }
\newlabel{asm:collision}{{2.4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-C}}Behavior Layer}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-D}}Local Motion Planning}{4}{}\protected@file@percent }
\citation{sabatino2015quadrotor}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The structure of behavior layer. The leaf of the tree structure are the possible behaviors an agent can take. The behavior to be take at every moment will be decided in this block.\relax }}{5}{}\protected@file@percent }
\newlabel{fig:behavior}{{2}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {III}system description of UAV-Robot Team System}{5}{}\protected@file@percent }
\newlabel{asm:cc again}{{3.1}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}motion planning of flying of UAV}{5}{}\protected@file@percent }
\newlabel{eq:uav}{{3}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The flowchart of local motion planning. The corresponding motion planning will be executed according to the behavior determined by the behavior layer. The terminator, exception, represents an exceptional condition that performs unconsidered behaviors. The reference path $r[k]$ is a sequence (or say a discrete signal) designed by a specific behavior block. $r[k]$ will convert to reference trajectory $r(t)$, an analog signal, by an A to D convertor.\relax }}{6}{}\protected@file@percent }
\newlabel{fig:LocalMotionPlanning}{{3}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The flowchart of Flying and Walking. In both two blocks, a smoothed path is obtained by post-processing first. Then the respective motion of behavior is designed. The final outputs of Flying and Walking are all reference path $r[k]$, but its value and dimension will vary according to the dimension of the system model.\relax }}{6}{}\protected@file@percent }
\newlabel{fig:FandW}{{4}{6}}
\citation{ourrobot}
\citation{kajita2001real}
\citation{ourrobot}
\citation{huang2001planning}
\citation{1241826}
\citation{lewis2012optimal}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}motion of walking of robot}{7}{}\protected@file@percent }
\newlabel{eq:robot}{{4}{7}}
\newlabel{eq:LIPM}{{6}{7}}
\newlabel{eq:output tracking}{{7}{7}}
\citation{9448458}
\citation{9075385}
\citation{chen2013human}
\citation{9306757}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Reference Tracking control}{8}{}\protected@file@percent }
\newlabel{eq:agent}{{8}{8}}
\newlabel{eq:control}{{9}{8}}
\newlabel{eq:agent d1}{{10}{8}}
\newlabel{eq:agent1}{{11}{8}}
\newlabel{eq:error, state eq}{{12}{8}}
\newlabel{eq:linear f1}{{13}{8}}
\newlabel{eq:agent output}{{14}{8}}
\newlabel{eq:error}{{15}{8}}
\citation{boyd1994linear}
\citation{boyd1994linear}
\newlabel{eq:smooth model}{{16}{9}}
\newlabel{eq:e_bar}{{17}{9}}
\newlabel{eq:e_hat}{{18}{9}}
\newlabel{eq:Kx}{{19}{9}}
\newlabel{eq:e_tilde}{{20}{9}}
\newlabel{eq:aug}{{21}{9}}
\newlabel{Hinf}{{22}{9}}
\newlabel{lemma1}{{1}{9}}
\newlabel{lemma2}{{2}{9}}
\newlabel{theorem1}{{1}{9}}
\newlabel{BMI1}{{25}{9}}
\newlabel{pf:1}{{26}{9}}
\newlabel{pf:2}{{27}{9}}
\newlabel{pf:3}{{IV}{9}}
\newlabel{eq:M}{{28}{10}}
\newlabel{eq:step1}{{29}{10}}
\newlabel{eq:step2}{{30}{10}}
\newlabel{LMI constraint}{{31}{10}}
\newlabel{eq:linear subsys}{{32}{10}}
\citation{ourrobot}
\bibstyle{unsrt}
\bibdata{citation}
\bibcite{8352646}{1}
\bibcite{9476736}{2}
\bibcite{9108245}{3}
\bibcite{9384209}{4}
\bibcite{8931370}{5}
\bibcite{6669235}{6}
\@writefile{toc}{\contentsline {section}{\numberline {V}simulation results}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VI}conclusion}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{REFERENCES}{11}{}\protected@file@percent }
\bibcite{paden2016survey}{7}
\bibcite{Khamis2015}{8}
\bibcite{elbanhawi2014sampling}{9}
\bibcite{liu2018survey}{10}
\bibcite{sabatino2015quadrotor}{11}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The flowchart of tracking control. The control scheme of UAV and robot is only different from the block, reference generator. The reason is that the underactuated nature of the UAV imposes the limitation on the control input and reference trajectory. By introducing this block, a general feedforward-linearized PID FTC for an agent in URTS is proposed.\relax }}{12}{}\protected@file@percent }
\newlabel{fig:tracking}{{5}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces An example of a S\&R area in URTS. This area is divided into $N_T$ areas, and $j$th team is responsible for $j$th area, $area_j$\relax }}{12}{}\protected@file@percent }
\newlabel{fig:SR_area}{{6}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The search tasks in $1$st team at the begining. The search tasks $T_j,j=1,2,...,5$ are to reach a destinition $q_{goal}$ as shown in figure. For robots, $q_{goal}$ will be passed to path planning algorithm to find a collision path. For UAV, the path is directly assigned due to the no-collision assumption as shown in figure.\relax }}{12}{}\protected@file@percent }
\newlabel{fig:S_task}{{7}{12}}
\bibcite{ourrobot}{12}
\bibcite{kajita2001real}{13}
\bibcite{huang2001planning}{14}
\bibcite{1241826}{15}
\bibcite{lewis2012optimal}{16}
\bibcite{9448458}{17}
\bibcite{9075385}{18}
\bibcite{chen2013human}{19}
\bibcite{9306757}{20}
\bibcite{boyd1994linear}{21}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The path planning tasks.\relax }}{13}{}\protected@file@percent }
\newlabel{fig:R_task}{{8}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The resuls of local motion planning of flying and walking.\relax }}{13}{}\protected@file@percent }
\newlabel{fig:sim:FandW}{{9}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The tracking error of UAV flying.\relax }}{13}{}\protected@file@percent }
\newlabel{fig:UAV, error, estimation}{{10}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The tracking error of robot walking.\relax }}{13}{}\protected@file@percent }
\newlabel{fig:robot, error, estimation}{{11}{13}}
\gdef \@abspage@last{13}
