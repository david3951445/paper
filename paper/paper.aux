\relax 
\citation{9700861}
\citation{8352646}
\citation{chen2019control}
\citation{9371292}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{}\protected@file@percent }
\citation{skaltsis2021survey}
\citation{zhang2018path}
\citation{9108245}
\citation{arbanas2018decentralized}
\citation{9384209}
\citation{olcay2017design}
\citation{8931370}
\citation{wang2022consensus}
\citation{6669235}
\citation{paden2016survey}
\@writefile{toc}{\contentsline {section}{\numberline {II}PRELIMINARIES OF URTS in S\&R usage}{3}{}\protected@file@percent }
\citation{khamis2015multi}
\citation{elbanhawi2014sampling}
\citation{liu2018survey}
\citation{elbanhawi2014sampling}
\citation{elbanhawi2014sampling}
\citation{yu2013multi}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The system architecture of each agent in URTS. The 2 blocks on left hand side are used to convert the low-level sensor information into high-level information, such as map $\mathcal  {C}$, current position $q_{start}$ and object information. The 5 blocks on right hand side are the flow of an agent performing a S\&R mission. From the top to the bottom, it is the decision of the goal configuration $q_{qoal}$, the planning of the path $(\sigma _n)$, the decision of the behavior $(\beta _n)$, the planning of the local motion path $r[k]$, and the low-level tracking control. A block with two vertical lines inside in flowchart represents a predefined process which has more detailed subprocesses. The Behavior Layer block is predefined in Fig. 2\hbox {}. The Local Motion Planning block is predefined in Fig. 3\hbox {}. The Tracking Control block is predefined in Fig. 5\hbox {}.\relax }}{4}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:sys}{{1}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Task Allocation}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Path Planning}{4}{}\protected@file@percent }
\newlabel{asm:collision}{{2.4}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-C}}Behavior Layer}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-D}}Local Motion Planning}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-E}}Tracking Control}{5}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  (a) The flowchart of Behavior Layer block in Fig. 1\hbox {} of each agent in URTS. The behavior to be took at every moment by each agent will be decided in this block. (b) The behavior set of each agent in URTS. The leaves of the tree structure are the possible behaviors an agent can take. For UAVs, the moving behavior set is predefined in (c). For robots, the moving behavior set is predefined in (d). (c) The moving behavior set of each UAV. (d) The moving behavior set of each robot.\relax }}{6}{}\protected@file@percent }
\newlabel{fig:behavior}{{2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  (a) The flowchart of Local Motion Planning block in Fig. 1\hbox {} of each agent in URTS. The corresponding motion planning of an agent will be executed according to the behavior determined by the behavior layer. The exception terminator in figure represents an exceptional condition that performs unconsidered behaviors. The reference path $r[k]$ is a sequence (or discrete signal) designed by a specific behavior block. For UAVs, the moving block is predefined in (b). For robots, the moving block is predefined in (c). (b) The moving block of each UAV where the flying block is predefined in Fig. 4\hbox {}. (c) The moving block of each robot where the walking block is predefined in Fig. 4\hbox {}.\relax }}{6}{}\protected@file@percent }
\newlabel{fig:LMP}{{3}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {III}system description of UAVs and biped robots in URTS}{6}{}\protected@file@percent }
\newlabel{asm:cc again}{{3.1}{6}}
\citation{sabatino2015quadrotor}
\citation{sabatino2015quadrotor}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The flowchart of flying block and walking block in Fig. 3\hbox {}. In both blocks, a smoothed path is obtained by post-processing first. Then the respective motion of behavior is designed. (a) The Flying block in Fig. 3\hbox {} of each UAV . By combining the position path $(\sigma '_n)$ and setting $\phi _d=0$ (let UAV fly without spinning), we have the reference path $r[k]$. (b) The Walking block in Fig. 3\hbox {}of each robot. Follow the process in Section IV-B, we have the reference path $r[k]$.\relax }}{7}{}\protected@file@percent }
\newlabel{fig:FandW}{{4}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}motion planning of flying of UAV}{7}{}\protected@file@percent }
\newlabel{eq:uav}{{3}{7}}
\citation{ourrobot}
\citation{kajita2001real}
\citation{ourrobot}
\citation{huang2001planning}
\citation{kajita2001real}
\citation{1241826}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}motion planning of walking of robot}{8}{}\protected@file@percent }
\newlabel{eq:robot}{{4}{8}}
\newlabel{eq:x_zmp}{{5}{8}}
\newlabel{eq:LIPM}{{6}{8}}
\citation{lewis2012optimal}
\citation{9834947}
\newlabel{eq:output tracking}{{7}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Tracking control of each agent in hybrid URTS}{9}{}\protected@file@percent }
\newlabel{eq:agent}{{8}{9}}
\newlabel{eq:control}{{9}{9}}
\citation{9075385}
\citation{chen2013human}
\citation{9834947}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  (a) The flowchart of Tracking Control block in Fig. 1\hbox {} of each agent in hybrid URTS. The controller block is predefined in (d). The controller block (the proposed general $H_\infty $ decentralized observer-based feedforward FTC scheme) is designed for a fully actuated agent dynamic model in (8\hbox {}) while the UAV is an underactuated system. It makes the designed control law $u(t)\in \mathbb  {R}^6$ and the actuator control input $u'(t)\in \mathbb  {R}^4$ different for UAV. The reference generator block is introduced to deal with this problem. For UAVs, the reference generator block is predefined in (b). For robots, the reference generator block is predefined in (c). (b) The reference generator block for each UAV. $u'(t)$ and $r(t)$ can be calculated from $u(t)$ and $r'(t)$ by inverse dynamic through the UAV dynamic model in (3\hbox {}). (c) The reference generator block for each robot. $u'(t)=u(t)$ and $r(t)=r'(t)$ since the robot dynamic model in (4\hbox {}) is fully actuated. (d) The proposed general $H_\infty $ decentralized observer-based feedforward FTC scheme for each agent in hybrid URTS.\relax }}{10}{}\protected@file@percent }
\newlabel{fig:tracking}{{5}{10}}
\newlabel{eq:UAV couple}{{10}{10}}
\newlabel{eq:robot couple}{{11}{10}}
\newlabel{eq:agent d1}{{12}{10}}
\citation{9306757}
\citation{9306757}
\newlabel{eq:agent1}{{13}{11}}
\newlabel{eq:error, state eq}{{14}{11}}
\newlabel{eq:linear f1}{{15}{11}}
\newlabel{eq:agent output}{{16}{11}}
\newlabel{eq:error}{{17}{11}}
\newlabel{eq:smooth model}{{18}{11}}
\newlabel{eq:e_bar}{{19}{11}}
\newlabel{eq:e_hat}{{20}{11}}
\newlabel{eq:u_fb}{{21}{11}}
\newlabel{eq:e_tilde}{{22}{11}}
\citation{boyd1994linear}
\citation{boyd1994linear}
\newlabel{eq:x_tilde}{{23}{12}}
\newlabel{Hinf}{{24}{12}}
\newlabel{lemma1}{{1}{12}}
\newlabel{lemma2}{{2}{12}}
\newlabel{theorem1}{{1}{12}}
\newlabel{BMI1}{{27}{12}}
\newlabel{pf:1}{{28}{12}}
\newlabel{pf:2}{{29}{12}}
\newlabel{pf:3}{{IV}{12}}
\newlabel{eq:M}{{30}{12}}
\newlabel{eq:step1}{{31}{13}}
\newlabel{eq:step2}{{32}{13}}
\newlabel{LMI constraint}{{33}{13}}
\newlabel{eq:linear subsys}{{34}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {V}simulation results}{14}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces An example of a S\&R area in URTS. This area is divided into $N_T$ areas, and $team_i$ is responsible for $area_i$.\relax }}{14}{}\protected@file@percent }
\newlabel{fig:SR_area}{{6}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The search tasks in the $i$th team and $(i+1)$th team at the begining. The search tasks $T_j,j=1,2,...,6$ are to reach some consecutive goals $q_{goal}$ (black dots in figure) obtained from task allocation block. For UAV, the sequence formed by $q_{goal}$ is directly the path $(\sigma _n)$ due to the no-collision assumption {\it  Assumption 2.4\hbox {}}. For robots, $q_{goal}$ will be passed to path planning block to find collision-free paths $(\sigma _n)$.\relax }}{14}{}\protected@file@percent }
\newlabel{fig:S_task}{{7}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The path planning result of robot using RRT algorithm. The block polygons represent the obstacle space $\mathcal  {C}_{obs}$.\relax }}{14}{}\protected@file@percent }
\newlabel{fig:R_task}{{8}{14}}
\citation{ourrobot}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The result of local motion planning of UAV flying.\relax }}{15}{}\protected@file@percent }
\newlabel{sim:flying}{{9}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The top view of result of local motion planning of robot walking. The joint path, i.e., reference path $r[k]$ will be obtained by solving IK with CoM, left foothold and right foothold path.\relax }}{15}{}\protected@file@percent }
\newlabel{sim:walking}{{10}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The trajectories of reference, state and estimated state of the UAV $\alpha _{1,1}$.\relax }}{15}{}\protected@file@percent }
\newlabel{fig:UAV, state}{{11}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The estimation of actuator fault of the UAV $\alpha _{1,1}$.\relax }}{16}{}\protected@file@percent }
\newlabel{fig:UAV, fa}{{12}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The estimation of sensor fault of the UAV $\alpha _{1,1}$.\relax }}{16}{}\protected@file@percent }
\newlabel{fig:UAV, fs}{{13}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces The control effort of the UAV $\alpha _{1,1}$.\relax }}{16}{}\protected@file@percent }
\newlabel{fig:UAV, control}{{14}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces The trajectories of reference, state and estimated state of the robot $\alpha _{1,5}$.\relax }}{16}{}\protected@file@percent }
\newlabel{fig:robot, state}{{15}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces The estimation of actuator fault of the robot $\alpha _{1,5}$.\relax }}{16}{}\protected@file@percent }
\newlabel{fig:robot, fa}{{16}{16}}
\citation{7456706}
\citation{7456706}
\citation{7456706}
\citation{7456706}
\citation{7456706}
\citation{7456706}
\citation{mySimulation}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces The estimation of sensor fault of the robot $\alpha _{1,5}$.\relax }}{17}{}\protected@file@percent }
\newlabel{fig:robot, fs}{{17}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces The control effort of the robot $\alpha _{1,5}$.\relax }}{17}{}\protected@file@percent }
\newlabel{fig:robot, control}{{18}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces The trajectories of reference, state and estimated state of the UAV $\alpha _{1,1}$ by traditional PID computed torque controller without FTC \cite  {7456706}.\relax }}{17}{}\protected@file@percent }
\newlabel{fig:uav, state, noFTC}{{19}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces The trajectories of reference, state and estimated state of the robot $\alpha _{1,5}$ by traditional PID computed torque controller without FTC \cite  {7456706}.\relax }}{17}{}\protected@file@percent }
\newlabel{fig:robot, state, noFTC}{{20}{17}}
\bibstyle{IEEEtran}
\bibdata{citation}
\bibcite{9700861}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces The simulation of team tracking of URTS for $team_i,i=1,2,3$ when perform search tasks. As shown in Fig. 6\hbox {}, the UAV and robot in URTS will be released along the direction of the road ($Y$-axis) and each team is responsible for an area. First, the respective tasks of each agent are determined by the task allocation algorithm. According to the task content, the agent will be determined a goal $q_{goal}$. As in Fig. 7\hbox {}, this simulation assumes that $team_i,i=1,2,3$ are assigned search tasks. Subsequently, the path $(\sigma _n)$ for each UAV is assigned and the collision-free path $(\sigma _n)$ for each robot is calculated by the path planning algorithm. Depending on the terrain environment, an appropriate behavior $(\beta _n)$ is determined to enable the agent to follow the path $(\sigma _n)$. A reference path $r[k]$ corresponding to a behavior is designed via local motion planning to enable an actual mechanical body to perform the behavior. Since this article only gives the motion planning method of flying (for UAV) and walking (for biped-robot), it is assumed that from $q_{start}$ to $q_{goal}$ are all flying or walking behaviors in this simulation. In this figure, we draw the smoothed path $(\sigma '_n)$ of each agent, which is the intermediate result of local motion planning as shown in Fig, 4\hbox {}. It represents the path that the agent is going to reach in the task space. According to $r[k]$ and the dynamic model of UAV and robot, the reference trajectory $r(t)$ of each agent is obtained. Finally, through the decentralized $H_\infty $ observer-based feedforward FTC scheme proposed in this paper, the team tracking result of the agents in $team_i, i=1,2,3$ in URTS are shown. Note that the above process is dynamic. If a block in a higher layer in URTS architecture makes a new decision that produces a new output, the lower blocks must recalculate based on it. Relatively, this simulation is the static result, that is, there is no re-decision from $q_{start}$ to $q_{goal}$.\relax }}{18}{}\protected@file@percent }
\newlabel{fig:URTS}{{21}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}conclusion}{18}{}\protected@file@percent }
\bibcite{8352646}{2}
\bibcite{chen2019control}{3}
\bibcite{9371292}{4}
\bibcite{skaltsis2021survey}{5}
\bibcite{zhang2018path}{6}
\bibcite{9108245}{7}
\bibcite{arbanas2018decentralized}{8}
\bibcite{9384209}{9}
\bibcite{olcay2017design}{10}
\bibcite{8931370}{11}
\bibcite{wang2022consensus}{12}
\bibcite{6669235}{13}
\bibcite{paden2016survey}{14}
\bibcite{khamis2015multi}{15}
\bibcite{elbanhawi2014sampling}{16}
\bibcite{liu2018survey}{17}
\bibcite{yu2013multi}{18}
\bibcite{sabatino2015quadrotor}{19}
\bibcite{ourrobot}{20}
\bibcite{kajita2001real}{21}
\bibcite{huang2001planning}{22}
\bibcite{1241826}{23}
\bibcite{lewis2012optimal}{24}
\bibcite{9834947}{25}
\bibcite{9075385}{26}
\bibcite{chen2013human}{27}
\bibcite{9306757}{28}
\bibcite{boyd1994linear}{29}
\bibcite{7456706}{30}
\bibcite{mySimulation}{31}
\@writefile{toc}{\contentsline {section}{REFERENCES}{19}{}\protected@file@percent }
\gdef \@abspage@last{19}
