\relax 
\citation{9700861}
\citation{8352646}
\citation{chen2019control}
\citation{9371292}
\citation{9476736}
\citation{zhang2018path}
\citation{9108245}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{}\protected@file@percent }
\citation{arbanas2018decentralized}
\citation{9384209}
\citation{olcay2017design}
\citation{8931370}
\citation{wang2022consensus}
\citation{6669235}
\citation{paden2016survey}
\citation{Khamis2015}
\@writefile{toc}{\contentsline {section}{\numberline {II}PRELIMINARIES OF URTS in S\&R usage}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Task Allocation}{3}{}\protected@file@percent }
\citation{elbanhawi2014sampling}
\citation{liu2018survey}
\citation{elbanhawi2014sampling}
\citation{elbanhawi2014sampling}
\citation{yu2013multi}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The system architecture of agent in URTS. The 2 blocks on left hand side are used to convert the low-level sensor information into high-level information, such as map, start point and object information. The 5 blocks on right hand side are the flow of an agent performing a S\&R mission. From the top to the bottom, it is the decision of the task position, the planning of the path, the decision of the behavior, the planning of the local motion trajectory, and the low-level tracking control.\relax }}{4}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:sys}{{1}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Path Planning}{4}{}\protected@file@percent }
\newlabel{asm:collision}{{2.4}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-C}}Behavior Layer}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-D}}Local Motion Planning}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-E}}Tracking Control}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}system description of UAVs and biped robots in URTS}{5}{}\protected@file@percent }
\newlabel{asm:cc again}{{3.1}{5}}
\citation{sabatino2015quadrotor}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The structure of behavior layer. The leaves of the tree structure are the possible behaviors an agent can take. The behavior to be took at every moment will be decided in this block.\relax }}{6}{}\protected@file@percent }
\newlabel{fig:behavior}{{2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The flowchart of local motion planning. The corresponding motion planning will be executed according to the behavior determined by the behavior layer. The exception terminator in figure represents an exceptional condition that performs unconsidered behaviors. The reference path $r[k]$ is a sequence (or say a discrete signal) designed by a specific behavior block. $r[k]$ will be converted to the desired reference trajectory $r(t)$, an analog signal, by an A to D convertor.\relax }}{6}{}\protected@file@percent }
\newlabel{fig:LocalMotionPlanning}{{3}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}motion planning of flying of UAV}{6}{}\protected@file@percent }
\newlabel{eq:uav}{{3}{6}}
\citation{ourrobot}
\citation{kajita2001real}
\citation{ourrobot}
\citation{huang2001planning}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The flowchart of Flying and Walking. In both two blocks, a smoothed path is obtained by post-processing first. Then the respective motion of behavior is designed. The final outputs of Flying and Walking are all reference path $r[k]$, but its value and dimension will vary according to the dimension of the system model.\relax }}{7}{}\protected@file@percent }
\newlabel{fig:FandW}{{4}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}motion of walking of robot}{7}{}\protected@file@percent }
\newlabel{eq:robot}{{4}{7}}
\citation{1241826}
\citation{lewis2012optimal}
\citation{9834947}
\citation{9075385}
\citation{chen2013human}
\newlabel{eq:LIPM}{{6}{8}}
\newlabel{eq:output tracking}{{7}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Reference Tracking control}{8}{}\protected@file@percent }
\newlabel{eq:agent}{{8}{8}}
\newlabel{eq:control}{{9}{8}}
\citation{9834947}
\citation{9306757}
\newlabel{eq:UAV couple}{{10}{9}}
\newlabel{eq:robot couple}{{11}{9}}
\newlabel{eq:agent d1}{{12}{9}}
\newlabel{eq:agent1}{{13}{9}}
\newlabel{eq:error, state eq}{{14}{9}}
\newlabel{eq:linear f1}{{15}{9}}
\newlabel{eq:agent output}{{16}{9}}
\newlabel{eq:error}{{17}{9}}
\newlabel{eq:smooth model}{{18}{9}}
\newlabel{eq:e_bar}{{19}{9}}
\newlabel{eq:e_hat}{{20}{9}}
\newlabel{eq:Kx}{{21}{9}}
\citation{boyd1994linear}
\citation{boyd1994linear}
\newlabel{eq:e_tilde}{{22}{10}}
\newlabel{eq:aug}{{23}{10}}
\newlabel{Hinf}{{24}{10}}
\newlabel{lemma1}{{1}{10}}
\newlabel{lemma2}{{2}{10}}
\newlabel{theorem1}{{1}{10}}
\newlabel{BMI1}{{27}{10}}
\newlabel{pf:1}{{28}{10}}
\newlabel{pf:2}{{29}{10}}
\newlabel{pf:3}{{IV}{10}}
\newlabel{eq:M}{{30}{10}}
\newlabel{eq:step1}{{31}{11}}
\newlabel{eq:step2}{{32}{11}}
\newlabel{LMI constraint}{{33}{11}}
\newlabel{eq:linear subsys}{{34}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The flowchart of tracking control. The control scheme of UAV and robot is only different from the block, reference generator. The reason is that the underactuated nature of the UAV imposes the limitation on the control input and reference trajectory. By introducing this block, a general feedforward-linearized PID FTC for an agent in URTS is proposed.\relax }}{12}{}\protected@file@percent }
\newlabel{fig:tracking}{{5}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {V}simulation results}{12}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces An example of a S\&R area in URTS. This area is divided into $N_T$ areas, and $team_i$ is responsible for $area_i$\relax }}{12}{}\protected@file@percent }
\newlabel{fig:SR_area}{{6}{12}}
\citation{ourrobot}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The search tasks in $i$th team at the begining. The search tasks $T_j,j=1,2,...,5$ are to reach some consecutive destinitions $q_{goal}$ (black dots in figure). For robots, $q_{goal}$ will be passed to path planning block to find collision-free paths $(\sigma _n)$. For UAV, the sequence formed by $q_{goal}$ is directly the path $(\sigma _n)$ due to the no-collision assumption.\relax }}{13}{}\protected@file@percent }
\newlabel{fig:S_task}{{7}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The path planning result of robot using RRT algorithm. The block polygons represent the obstacle space $\mathcal  {C}_{obs}$.\relax }}{13}{}\protected@file@percent }
\newlabel{fig:R_task}{{8}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The result of local motion planning of UAV flying.\relax }}{13}{}\protected@file@percent }
\newlabel{sim:flying}{{9}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The top view of result of local motion planning of robot walking. The joint path, i.e., reference path $r[k]$ will be obtained by solving IK with CoM, left foothold and right foothold path.\relax }}{13}{}\protected@file@percent }
\newlabel{sim:walking}{{10}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The trajectories of reference, state and estimated state of the UAV $\alpha _{i,1}$\relax }}{14}{}\protected@file@percent }
\newlabel{fig:UAV, state}{{11}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The estimation of actuator fault of the UAV $\alpha _{i,1}$\relax }}{14}{}\protected@file@percent }
\newlabel{fig:UAV, fa}{{12}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The estimation of sensor fault of the UAV $\alpha _{i,1}$\relax }}{14}{}\protected@file@percent }
\newlabel{fig:UAV, fs}{{13}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces The control effort of the UAV $\alpha _{i,1}$\relax }}{14}{}\protected@file@percent }
\newlabel{fig:UAV, control}{{14}{14}}
\bibstyle{unsrt}
\bibdata{citation}
\bibcite{9700861}{1}
\bibcite{8352646}{2}
\bibcite{chen2019control}{3}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces The trajectories of reference, state and estimated state of the robot $\alpha _{i,2}$\relax }}{15}{}\protected@file@percent }
\newlabel{fig:robot, state}{{15}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces The estimation of actuator fault of the robot $\alpha _{i,2}$.\relax }}{15}{}\protected@file@percent }
\newlabel{fig:robot, fa}{{16}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces The estimation of sensor fault of the robot $\alpha _{i,2}$\relax }}{15}{}\protected@file@percent }
\newlabel{fig:robot, fs}{{17}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces The control effort of the robot $\alpha _{i,2}$\relax }}{15}{}\protected@file@percent }
\newlabel{fig:robot, control}{{18}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}conclusion}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{REFERENCES}{15}{}\protected@file@percent }
\bibcite{9371292}{4}
\bibcite{9476736}{5}
\bibcite{zhang2018path}{6}
\bibcite{9108245}{7}
\bibcite{arbanas2018decentralized}{8}
\bibcite{9384209}{9}
\bibcite{olcay2017design}{10}
\bibcite{8931370}{11}
\bibcite{wang2022consensus}{12}
\bibcite{6669235}{13}
\bibcite{paden2016survey}{14}
\bibcite{Khamis2015}{15}
\bibcite{elbanhawi2014sampling}{16}
\bibcite{liu2018survey}{17}
\bibcite{yu2013multi}{18}
\bibcite{sabatino2015quadrotor}{19}
\bibcite{ourrobot}{20}
\bibcite{kajita2001real}{21}
\bibcite{huang2001planning}{22}
\bibcite{1241826}{23}
\bibcite{lewis2012optimal}{24}
\bibcite{9834947}{25}
\bibcite{9075385}{26}
\bibcite{chen2013human}{27}
\bibcite{9306757}{28}
\bibcite{boyd1994linear}{29}
\gdef \@abspage@last{16}
